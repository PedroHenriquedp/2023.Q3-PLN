{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMzqE/oWeLnQKCW66UA0IB1",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/adalves-ufabc/2023.Q3-PLN/blob/main/2023_Q3_PLN_OpenAI_1_3_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y6QILOdpOjwv"
      },
      "source": [
        "# **Processamento de Linguagem Natural [2023.Q3]**\n",
        "Prof. Alexandre Donizeti Alves"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8m67OOx9MX_3"
      },
      "source": [
        "**OpenAI [versão 1.3.5]**\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "`Atualizado em novembro de 2023`"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Versão do Python no Google Colab\n",
        "\n",
        "import sys\n",
        "\n",
        "print(sys.version)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qOcDKr2GrDQY",
        "outputId": "ec53c9bd-4957-4eaf-c5aa-24b464279acb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3.10.12 (main, Jun 11 2023, 05:26:28) [GCC 11.4.0]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openai"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PW0blFkGqx8x",
        "outputId": "c95b5a16-d924-41e6-f1ee-2e4911d96e6f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.3.5)\n",
            "Requirement already satisfied: anyio<4,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (1.10.13)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.5 in /usr/local/lib/python3.10/dist-packages (from openai) (4.5.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (3.4)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.3.0)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<4,>=3.5.0->openai) (1.1.3)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2023.7.22)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.2)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Versão da API da OpenAI\n",
        "import openai\n",
        "\n",
        "print(openai.__version__)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PGa7szHHrJyP",
        "outputId": "4228c7de-1d72-4a07-8f53-e5943787b72d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.3.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from getpass import getpass\n",
        "\n",
        "OPENAI_API_KEY = getpass()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDseDeBEsIVm",
        "outputId": "01fe8ec0-4833-4ce5-96f1-0fe8883563c5"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "··········\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "    messages=[\n",
        "        {\n",
        "            \"role\": \"user\",\n",
        "            \"content\": \"Diga que isso é um teste\",\n",
        "        }\n",
        "    ],\n",
        "    model=\"gpt-3.5-turbo\",\n",
        ")"
      ],
      "metadata": {
        "id": "KwtcALh0tjLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "type(resposta)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6BPIqFasuO1P",
        "outputId": "c47a85e4-f680-4aed-edc5-c3ee07c3832b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "openai.types.chat.chat_completion.ChatCompletion"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resposta.json()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "etBkk1Xgu1xb",
        "outputId": "ef1dbd72-2d2d-4719-de13-2f267c1eae28"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'{\"id\": \"chatcmpl-8PZZVQTQ2kzBY3Nl0qTBgZoOFPnSR\", \"choices\": [{\"finish_reason\": \"stop\", \"index\": 0, \"message\": {\"content\": \"Isso \\\\u00e9 um teste.\", \"role\": \"assistant\", \"function_call\": null, \"tool_calls\": null}}], \"created\": 1701105629, \"model\": \"gpt-3.5-turbo-0613\", \"object\": \"chat.completion\", \"system_fingerprint\": null, \"usage\": {\"completion_tokens\": 6, \"prompt_tokens\": 14, \"total_tokens\": 20}}'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z5B9Q5Q6vYgE",
        "outputId": "b3fa85d7-dd45-48cd-a825-02af7a1e033c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Isso é um teste.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title *Chat Completions* (Correção Gramatical)\n",
        "\n",
        "mensagem_sistema = 'Você receberá instruções e sua tarefa é corrigir para o Português'\n",
        "mensagem_usuario = \"o mecado estava fexado.\"\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resposta = cliente.chat.completions.create(\n",
        "   model = \"gpt-3.5-turbo\",\n",
        "   messages = [{\"role\": \"system\", \"content\": mensagem_sistema},\n",
        "               {\"role\": \"user\", \"content\": mensagem_usuario}]\n",
        ")"
      ],
      "metadata": {
        "id": "J8_jNXcNtWmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resposta.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cZ3gZoGvv3kK",
        "outputId": "3ad2d0cb-7f3f-408b-e55f-f741db7abe9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "O mercado estava fechado.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Lista de Modelos**"
      ],
      "metadata": {
        "id": "YidZ8JZbwoTe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "# obter a lista de modelos\n",
        "modelos = cliente.models.list()"
      ],
      "metadata": {
        "id": "xjBBIDFowqFa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir total de modelos\n",
        "print(len(modelos.data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ho-tNOdQxCpQ",
        "outputId": "cd645c97-0b73-47a1-c3c9-63bfbc410a52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# imprimir os nomes dos modelos\n",
        "for modelo in modelos.data:\n",
        "   print(modelo.id)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5LwybwgoxWmK",
        "outputId": "20247cf6-1f8f-4d4f-f6bf-ce7b3d52a0fa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "text-search-babbage-doc-001\n",
            "gpt-3.5-turbo-16k\n",
            "curie-search-query\n",
            "text-davinci-003\n",
            "text-search-babbage-query-001\n",
            "babbage\n",
            "gpt-3.5-turbo-1106\n",
            "babbage-search-query\n",
            "text-babbage-001\n",
            "text-similarity-davinci-001\n",
            "davinci-similarity\n",
            "code-davinci-edit-001\n",
            "curie-similarity\n",
            "babbage-search-document\n",
            "curie-instruct-beta\n",
            "text-search-ada-doc-001\n",
            "davinci-instruct-beta\n",
            "gpt-3.5-turbo-instruct\n",
            "text-similarity-babbage-001\n",
            "text-search-davinci-doc-001\n",
            "gpt-3.5-turbo-instruct-0914\n",
            "babbage-similarity\n",
            "text-embedding-ada-002\n",
            "davinci-search-query\n",
            "text-similarity-curie-001\n",
            "text-davinci-001\n",
            "text-search-davinci-query-001\n",
            "ada-search-document\n",
            "ada-code-search-code\n",
            "babbage-002\n",
            "davinci-002\n",
            "davinci-search-document\n",
            "curie-search-document\n",
            "babbage-code-search-code\n",
            "text-search-ada-query-001\n",
            "code-search-ada-text-001\n",
            "gpt-3.5-turbo-16k-0613\n",
            "babbage-code-search-text\n",
            "code-search-babbage-code-001\n",
            "ada-search-query\n",
            "ada-code-search-text\n",
            "tts-1-hd\n",
            "text-search-curie-query-001\n",
            "text-davinci-002\n",
            "text-davinci-edit-001\n",
            "code-search-babbage-text-001\n",
            "tts-1-hd-1106\n",
            "ada\n",
            "text-ada-001\n",
            "ada-similarity\n",
            "code-search-ada-code-001\n",
            "text-similarity-ada-001\n",
            "canary-whisper\n",
            "whisper-1\n",
            "text-search-curie-doc-001\n",
            "text-curie-001\n",
            "curie\n",
            "canary-tts\n",
            "tts-1\n",
            "gpt-3.5-turbo-0613\n",
            "gpt-3.5-turbo-0301\n",
            "gpt-3.5-turbo\n",
            "davinci\n",
            "dall-e-2\n",
            "tts-1-1106\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função para verificar se um modelo existe\n",
        "\n",
        "def verificar_modelo(nome_modelo):\n",
        "   modelos = cliente.models.list()\n",
        "   for modelo in modelos.data:\n",
        "      if modelo.id == nome_modelo:\n",
        "         return True\n",
        "   return False"
      ],
      "metadata": {
        "id": "q2qeGjE5xebY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(verificar_modelo(\"text-davinci-003\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "61fQ69lrxqXo",
        "outputId": "878a4283-b5b9-4ef9-ff62-53248ffcddc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#@title Função para verificar se parte do nome está na lista de modelos\n",
        "\n",
        "def verificar_modelo_parcial(parte_nome):\n",
        "   modelos = cliente.models.list()\n",
        "   nomes_modelos = [modelo.id for modelo in modelos.data]\n",
        "   modelos_identificados = [modelo for modelo in nomes_modelos if parte_nome.lower() in modelo.lower()]\n",
        "\n",
        "   return modelos_identificados"
      ],
      "metadata": {
        "id": "wVxNyS6BxtHX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(verificar_modelo_parcial(\"gpt\"))"
      ],
      "metadata": {
        "id": "A9E1OrbLx5zC",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8a566cbc-7fac-406c-b2a8-d33aa3197601"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['gpt-3.5-turbo-16k', 'gpt-3.5-turbo-1106', 'gpt-3.5-turbo-instruct', 'gpt-3.5-turbo-instruct-0914', 'gpt-3.5-turbo-16k-0613', 'gpt-3.5-turbo-0613', 'gpt-3.5-turbo-0301', 'gpt-3.5-turbo']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Chat completion**"
      ],
      "metadata": {
        "id": "d_f17a0_zf0K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "cliente = OpenAI( api_key = OPENAI_API_KEY )\n",
        "\n",
        "resultado = cliente.chat.completions.create(\n",
        "  model=\"gpt-3.5-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"Você é um assistente útil.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Olá\"}\n",
        "  ]\n",
        ")"
      ],
      "metadata": {
        "id": "y3mztygpzj-g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(resultado.choices[0].message.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DLKGR6Ufz2iV",
        "outputId": "d2b4109c-9ad2-417f-a3b6-a1ba062862c3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Olá! Como posso ajudar você hoje?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Referências**:\n",
        "\n",
        "https://github.com/openai/openai-python\n",
        "\n",
        "https://platform.openai.com/docs/api-reference"
      ],
      "metadata": {
        "id": "e4ObS3lkuiyX"
      }
    }
  ]
}